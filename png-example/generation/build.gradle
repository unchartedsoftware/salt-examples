/**
 * $ ./gradlew
 * The default task will build the project and run the test suite inside
 * your local spark environment (spark-submit must be on the PATH).
 *
 * A coverage report will be present at build/reports/scoverage/index.html
 *
 * TODO integrate https://github.com/kt3k/coveralls-gradle-plugin
 */

group = 'software.uncharted.salt'
version = '4.0.0'

project.ext {
  scalaBinaryVersion = '2.11'
  scalaVersion = '2.11.8'
  sparkVersion = '2.0.0'
  saltVersion = '4.0.0'
  sparkCsvVersion = '1.0.3'
  dataFile = "taxi_one_day.csv"
  dataSource = "http://assets.oculusinfo.com/salt/sample-data/${dataFile}"
}

apply from: '../../root.gradle'
apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'maven'
apply plugin: 'idea'

sourceCompatibility = 1.7
targetCompatibility = 1.7

repositories {
  mavenLocal()
  mavenCentral()
}

configurations {
  provided
  compile.extendsFrom provided
}

jar {
  baseName = 'salt-png-example'
  version =  version
  dependsOn configurations.runtime
  from {
    (configurations.runtime - configurations.provided).collect {
      it.isDirectory() ? it : zipTree(it)
    }
  } {
    exclude "META-INF/*.SF"
    exclude "META-INF/*.DSA"
    exclude "META-INF/*.RSA"
  }
}

task createDataDirectory(overwrite: true, type: Exec) {
  executable = 'docker'
  args = ["exec", project.name, "mkdir", "-p", "/opt/data"]
}

task downloadData(overwrite: true, type: Exec) {
  ignoreExitValue = true
  executable = 'docker'
  args = ["exec", project.name, "wget", "-P", "/opt/data", "${dataSource}"]
}

task run(overwrite: true, type: Exec, dependsOn: [startGenEnv, createDataDirectory, downloadData, assemble]) {
  executable = 'docker'
  args = ["exec", project.name, "spark-submit", "--class","software.uncharted.salt.examples.png.Main","/opt/salt/build/libs/salt-png-example-${version}.jar", "/opt/data/${dataFile}", "/opt/output"]
}

dependencies {
  compile "software.uncharted.salt:salt-core:${saltVersion}"

  //scala
  provided "org.scala-lang:scala-library:${scalaVersion}"

  //spark
  provided "org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}"
  provided "org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}"
  provided "org.scala-lang:scala-library:${scalaBinaryVersion}"

  compile "com.databricks:spark-csv_${scalaBinaryVersion}:${sparkCsvVersion}"
}

task wrapper(type: Wrapper) {
  gradleVersion = '2.13'
}

idea {
    module {
        inheritOutputDirs = false
        outputDir = file("$buildDir/classes/main/")
    }
}

createDataDirectory.mustRunAfter startGenEnv
downloadData.mustRunAfter createDataDirectory

defaultTasks 'run'
