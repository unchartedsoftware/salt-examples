/**
 * $ ./gradlew
 * The default task will build the project and run the test suite inside
 * your local spark environment (spark-submit must be on the PATH).
 *
 * A coverage report will be present at build/reports/scoverage/index.html
 *
 * TODO integrate https://github.com/kt3k/coveralls-gradle-plugin
 */

group = 'software.uncharted.salt'
version = '4.0.0'

project.ext {
  scalaBinaryVersion = '2.11'
  scalaVersion = '2.11.8'
  sparkVersion = '2.0.0'
  saltVersion = '4.0.0'
  sparkpipeVersion = '0.9.8'
  sqliteVersion = '3.8.11.2'
  sparkCsvVersion = '1.0.3'
  dataFile = "ubuntu-filelist.csv"
  dataSource = "http://assets.oculusinfo.com/salt/sample-data/${dataFile}"
}

apply from: '../../root.gradle'
apply plugin: 'idea'
apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'scala'

sourceCompatibility = 1.7
targetCompatibility = 1.7

repositories {
  mavenLocal()
  mavenCentral()
}

configurations {
  provided
  compile.extendsFrom provided
}

jar {
  baseName = 'salt-hierarchical-pie-example'
  version =  version
  dependsOn configurations.runtime
  from {
    (configurations.runtime - configurations.provided).collect {
      it.isDirectory() ? it : zipTree(it)
    }
  } {
    exclude "META-INF/*.SF"
    exclude "META-INF/*.DSA"
    exclude "META-INF/*.RSA"
  }
}

task run(overwrite: true, type: Exec, dependsOn: [startGenEnv, createDataDirectory, downloadData, assemble]) {
  executable = 'docker'
  args = ["exec", project.name, "spark-submit", "--class", "software.uncharted.salt.examples.hpie.Main", "/opt/salt/build/libs/salt-hierarchical-pie-example-${version}.jar", "/opt/data/${dataFile}", "/opt/output"]
}

dependencies {
    //salt
    compile "software.uncharted.salt:salt-core:${saltVersion}"

    //uncharted spark pipeline
    compile "software.uncharted.sparkpipe:sparkpipe-core:${sparkpipeVersion}"

    //sqlite
    compile "org.xerial:sqlite-jdbc:${sqliteVersion}"

    //scala
    provided "org.scala-lang:scala-library:${scalaVersion}"

    //spark
    provided "org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.scala-lang:scala-library:${scalaBinaryVersion}"

    compile "com.databricks:spark-csv_${scalaBinaryVersion}:${sparkCsvVersion}"
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.13'
}

idea {
    module {
        inheritOutputDirs = false
        outputDir = file("$buildDir/classes/main/")
    }
}

createDataDirectory.mustRunAfter startGenEnv
downloadData.mustRunAfter createDataDirectory

defaultTasks 'run'
